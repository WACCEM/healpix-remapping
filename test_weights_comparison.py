#!/usr/bin/env python3
"""
Test script to compare weight files generated by notebook vs Python script
"""

import numpy as np
import xarray as xr
import healpix as hp
import easygems.remap as egr
from pathlib import Path

def test_weights_comparison():
    """Compare the weights generated by both approaches"""
    
    # Load the same input file
    input_file = "/pscratch/sd/w/wcmca1/GPM/IR_IMERG_Combined_V06B/2019/merg_2019010100_4km-pixel.nc"
    ds = xr.open_dataset(input_file)
    
    print(f"Input grid: {ds.lon.shape}, {ds.lat.shape}")
    print(f"Lon range: {ds.lon.min().values:.3f} to {ds.lon.max().values:.3f}")
    print(f"Lat range: {ds.lat.min().values:.3f} to {ds.lat.max().values:.3f}")
    
    # Generate weights using the same function
    order = 9
    nside = hp.order2nside(order)
    npix = hp.nside2npix(nside)
    
    # Get HEALPix pixel coordinates
    hp_lon, hp_lat = hp.pix2ang(
        nside=nside, ipix=np.arange(npix), lonlat=True, nest=True
    )
    
    # Create 2D meshgrid from 1D lat/lon arrays
    lon_2d, lat_2d = np.meshgrid(ds.lon.values, ds.lat.values)
    
    # Flatten to 1D for weight computation
    source_lon = lon_2d.flatten()
    source_lat = lat_2d.flatten()
    
    print(f"Source grid flattened: {len(source_lon)} points")
    print(f"Target HEALPix: {len(hp_lon)} points")
    
    # Check if this is a global grid
    lon_range = np.max(ds.lon.values) - np.min(ds.lon.values)
    print(f"Longitude range: {lon_range:.3f} degrees")
    
    if lon_range >= 359:  # Global grid
        print("Detected global grid - handling periodicity")
        
        # Extend grid periodically in longitude
        lon_extended = np.hstack([source_lon - 360, source_lon, source_lon + 360])
        lat_extended = np.tile(source_lat, 3)
        
        print(f"Extended grid: {len(lon_extended)} points")
        
        # Compute weights using extended grid
        weights = egr.compute_weights_delaunay(
            points=(lon_extended, lat_extended), 
            xi=(hp_lon, hp_lat)
        )
        
        # Remap source indices back to original grid size
        original_size = len(source_lon)
        weights = weights.assign(src_idx=weights.src_idx % original_size)
        
    else:
        print("Detected regional grid - no periodicity handling")
        weights = egr.compute_weights_delaunay(
            points=(source_lon, source_lat), 
            xi=(hp_lon, hp_lat)
        )
    
    print(f"Weights computed: {weights.src_idx.shape}, {weights.weights.shape}")
    print(f"Weight dimensions: {list(weights.weights.dims)}")
    
    # Check weight statistics
    print(f"\nWeight statistics:")
    print(f"Valid pixels: {weights.valid.sum().values} / {len(weights.valid)}")
    print(f"Source index range: {weights.src_idx.min().values} to {weights.src_idx.max().values}")
    # Fix dimension name for weight sum
    weight_dim = list(weights.weights.dims)[-1]  # Get the last dimension name
    print(f"Weight sum per pixel (should be ~1): min={weights.weights.sum(dim=weight_dim).min().values:.6f}, max={weights.weights.sum(dim=weight_dim).max().values:.6f}")
    print(f"Weight range: {weights.weights.min().values:.6f} to {weights.weights.max().values:.6f}")
    
    # Save test weights
    test_weights_file = "test_weights_comparison.nc"
    weights.to_netcdf(test_weights_file)
    print(f"\nSaved test weights to {test_weights_file}")
    
    # Load existing weight files if they exist
    notebook_weights_file = "/pscratch/sd/w/wcmca1/GPM/weights/imerg_to_healpix_z9_weights.nc"
    script_weights_file = "weights_merg_2019010100_4km-pixel_z9.nc"
    
    for weight_file, name in [(notebook_weights_file, "notebook"), (script_weights_file, "script")]:
        if Path(weight_file).exists():
            print(f"\n{name.upper()} weights file: {weight_file}")
            w = xr.open_dataset(weight_file)
            print(f"  Shape: {w.src_idx.shape}, {w.weights.shape}")
            print(f"  Dimensions: {list(w.weights.dims)}")
            print(f"  Valid pixels: {w.valid.sum().values} / {len(w.valid)}")
            print(f"  Source index range: {w.src_idx.min().values} to {w.src_idx.max().values}")
            # Get the right dimension name for this weight file
            w_weight_dim = list(w.weights.dims)[-1]
            print(f"  Weight sum per pixel: min={w.weights.sum(dim=w_weight_dim).min().values:.6f}, max={w.weights.sum(dim=w_weight_dim).max().values:.6f}")
            print(f"  Weight range: {w.weights.min().values:.6f} to {w.weights.max().values:.6f}")
            
            # Compare with our test weights
            if np.array_equal(w.src_idx.values, weights.src_idx.values):
                print(f"  ✓ Source indices MATCH test weights")
            else:
                print(f"  ✗ Source indices DIFFER from test weights")
                
            if np.allclose(w.weights.values, weights.weights.values, rtol=1e-10):
                print(f"  ✓ Weight values MATCH test weights")
            else:
                print(f"  ✗ Weight values DIFFER from test weights")
                diff_max = np.abs(w.weights.values - weights.weights.values).max()
                print(f"    Max difference: {diff_max}")
        else:
            print(f"\n{name.upper()} weights file not found: {weight_file}")

if __name__ == "__main__":
    test_weights_comparison()
