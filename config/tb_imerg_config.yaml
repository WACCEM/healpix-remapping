# IMERG to HEALPix Processing Configuration
# Optimized for NERSC Perlmutter (128-core, 512GB RAM compute nodes)

# Data paths
input_base_dir: "/pscratch/sd/w/wcmca1/GPM/IR_IMERG_Combined_V07B/"
output_base_dir: "/pscratch/sd/w/wcmca1/GPM/healpix/"
output_basename: "IR_IMERG_V7"
weights_dir: "/pscratch/sd/w/wcmca1/GPM/weights/"

# File search pattern configuration
# These parameters control how files are discovered and filtered by date
# Filename format: merg_YYYYMMDDhh_10km-pixel.nc (e.g., merg_2020010100_10km-pixel.nc)
date_pattern: "_(\\d{10})_"    # Regex to extract YYYYMMDDhh (10 digits between underscores)
date_format: "%Y%m%d%H"        # strptime format: YYYY=year, MM=month, DD=day, HH=hour
use_year_subdirs: true         # Files organized in yearly subdirectories (YYYY/)
file_glob: "merg_*.nc"         # Glob pattern to match files (merg_*.nc)

# Processing parameters  
default_zoom: 9
time_chunk_size: 24  # 1 day worth of 1-hour data (balance memory vs parallelism)
time_average: null  # Options: null (no averaging), "1h" (1-hour), "3h", "6h", "1d" (daily), etc.
convert_time: True   # Convert cftime.DatetimeJulian to standard datetime64 for pandas compatibility

# Spatial dimension configuration (OPTIONAL)
# If not specified, spatial dimensions will be auto-detected from the first data file
# Use this to override auto-detection or for explicit control
# spatial_dimensions:
#   lat: -1   # -1 means no chunking (keep full dimension)
#   lon: -1
# 
# Examples for different datasets:
#   IMERG/IR_IMERG: {lat: -1, lon: -1}
#   ERA5: {latitude: -1, longitude: -1}
#   E3SM: {ncol: -1}
#   CMIP6: {lat: -1, lon: -1} or {latitude: -1, longitude: -1} (varies by model)

# Time dimension configuration (OPTIONAL)
# Name of the time/concatenation dimension (default: 'time')
# Only specify if your dataset uses a different name
# concat_dim: "time"
#
# Examples for different datasets:
#   Most datasets: "time" (default)
#   WRF: "Time" or "Times"
#   Some CMIP6: "time_counter"

# Note: spatial_chunk_size is automatically computed based on zoom level using chunk_tools.compute_chunksize()
force_recompute: False    # Force recompute weight file even if it exists

# Dask configuration - SIMPLIFIED for I/O-intensive zarr writes
# Hardware: 2x AMD EPYC 7763 (128 cores total), 512 GB RAM
# Strategy: Fewer workers with more memory to avoid pause/deadlock issues
dask:
  n_workers: 16               # Fewer workers = less memory contention during I/O
  threads_per_worker: 1      # Moderate threading for I/O operations
  # memory_limit: "30GB"        # Auto-calculated: 80% of 512GB / 4 workers â‰ˆ 102GB per worker
  
  # Note: memory_limit commented out to use auto-calculation from system memory
  # This prevents worker pausing at 80% that causes zarr write deadlocks
  
# Compression settings for Zarr
compression:
  compressor: "zstd"
  compressor_level: 3
  dtype: "float32"

# Variable filtering
skip_variables:
  - "*_bnds"
  - "*_bounds"
  - "time_bnds"
  - "lat_bnds" 
  - "lon_bnds"

# Only process variables with these dimensions
required_dimensions:
  - ["time", "lat", "lon"]
  - ["time", "lon", "lat"]
