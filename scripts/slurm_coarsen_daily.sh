#!/bin/bash
#SBATCH --job-name=coarsen_ifs
#SBATCH --account=m1867
#SBATCH --qos=shared
#SBATCH --constraint=cpu
#SBATCH --time=01:00:00
#SBATCH --nodes=1
#SBATCH --ntasks=1
#SBATCH --cpus-per-task=1
#SBATCH --mem=20GB
#SBATCH --output=logs/coarsen_%A_%a.out
#SBATCH --error=logs/coarsen_%A_%a.err
#SBATCH --array=1-366%2
#SBATCH --mail-user=zhe.feng@pnnl.gov
#SBATCH --mail-type=END

# SLURM job array script for coarsening HEALPix data - processes multiple days in parallel
# 
# This script uses SLURM job arrays to process multiple days efficiently.
# Each array task processes one day from a task list file.
#
# Usage:
#   # First generate the task list:
#   python submit_daily_coarsen_jobs.py --start_date 2020-01-01 --end_date 2020-12-31 --generate_only
#
#   # Then submit the job array:
#   sbatch slurm_coarsen_daily.sh
#
# The --array parameter controls:
#   - Range: 1-366 means tasks 1 through 366
#   - Throttle: %2 means max 2 tasks running simultaneously (recommended for remote data access)
#
# Adjust these in the #SBATCH --array line above or when submitting:
#   sbatch --array=1-31%2 slurm_coarsen_daily.sh  # Process 31 days, max 2 at a time

# ============================================================================
# CONFIGURATION - Modify these variables as needed
# ============================================================================

# Task list file (generated by submit_daily_coarsen_jobs.py)
TASK_LIST="${TASK_LIST:-task_list.txt}"

# Script location
SCRIPT_DIR="/global/homes/f/feng045/program/hackathon/healpix-remapping/scripts"
SCRIPT_PATH="${SCRIPT_DIR}/coarsen_catalog_ifs.py"

# Python environment
CONDA_ENV="/global/common/software/m1867/python/hackathon"

# Output directory
OUTPUT_DIR=${OUTPUT_DIR:-"/pscratch/sd/w/wcmca1/hackathon/healpix/ifs_tco3999_rcbmf/"}

# ============================================================================
# JOB EXECUTION - Generally no need to modify below this line
# ============================================================================

# Print job information
echo "========================================"
echo "SLURM Job Array Information"
echo "========================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Array Job ID: $SLURM_ARRAY_JOB_ID"
echo "Array Task ID: $SLURM_ARRAY_TASK_ID"
echo "Job Name: $SLURM_JOB_NAME"
echo "Node: $(hostname)"
echo "Start Time: $(date)"
echo ""

# Check if task list exists
if [ ! -f "$TASK_LIST" ]; then
    echo "ERROR: Task list file not found: $TASK_LIST"
    echo "Generate it with: python submit_daily_coarsen_jobs.py --start_date ... --end_date ... --generate_only"
    exit 1
fi

# Read the specific line for this array task
TASK_LINE=$(sed -n "${SLURM_ARRAY_TASK_ID}p" "$TASK_LIST")

if [ -z "$TASK_LINE" ]; then
    echo "ERROR: No task found for array task ID $SLURM_ARRAY_TASK_ID"
    exit 1
fi

# Parse the task line: START_DATE END_DATE TARGET_ZOOM TIME_SUBSAMPLE_FACTOR
read -r START_DATE END_DATE TARGET_ZOOM TIME_SUBSAMPLE_FACTOR <<< "$TASK_LINE"

echo "========================================"
echo "Processing Configuration"
echo "========================================"
echo "Task List: $TASK_LIST"
echo "Task Line: $TASK_LINE"
echo "Date Range: $START_DATE to $END_DATE"
echo "Target Zoom: $TARGET_ZOOM"
echo "Time Subsample Factor: $TIME_SUBSAMPLE_FACTOR"
echo "Output Directory: $OUTPUT_DIR"
echo "Script: $SCRIPT_PATH"
echo "Conda Environment: $CONDA_ENV"
echo "========================================"
echo ""

# Check if script exists
if [ ! -f "$SCRIPT_PATH" ]; then
    echo "ERROR: Script not found: $SCRIPT_PATH"
    exit 1
fi

# Load required modules
echo "Loading modules..."
module load python
module list
echo ""

# Activate conda environment
echo "Activating conda environment: $CONDA_ENV"
source activate $CONDA_ENV
if [ $? -ne 0 ]; then
    echo "ERROR: Failed to activate conda environment"
    exit 1
fi
echo "Python: $(which python)"
echo "Python version: $(python --version)"
echo ""

# Create output directory if it doesn't exist
mkdir -p "$OUTPUT_DIR"

# Run the coarsening script
echo "========================================"
echo "Starting coarsening process..."
echo "========================================"
echo ""

python "$SCRIPT_PATH" \
    --target_zoom $TARGET_ZOOM \
    --time_subsample_factor $TIME_SUBSAMPLE_FACTOR \
    --start_date $START_DATE \
    --end_date $END_DATE \
    --overwrite

# Capture exit code
EXIT_CODE=$?

echo ""
echo "========================================"
echo "Job Completion"
echo "========================================"
echo "End Time: $(date)"
echo "Exit Code: $EXIT_CODE"

if [ $EXIT_CODE -eq 0 ]; then
    echo "Status: SUCCESS ✅"
else
    echo "Status: FAILED ❌"
fi
echo "========================================"

exit $EXIT_CODE
